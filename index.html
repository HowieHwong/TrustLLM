
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Trustworthiness in Large Language Models">
      
      
      
      
      
        <link rel="next" href="guides/generation_details.html">
      
      
      <link rel="icon" href="img.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.14">
    
    
      
        <title>TrustLLM</title>
      
    
    
      <link rel="stylesheet" href="assets/stylesheets/main.342714a4.min.css">
      
        
        <link rel="stylesheet" href="assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Ubuntu:300,300i,400,400i,700,700i%7CUbuntu+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Ubuntu";--md-code-font:"Ubuntu Mono"}</style>
      
    
    
      <link rel="stylesheet" href="stylesheets/extra.css">
    
    <script>__md_scope=new URL(".",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="black" data-md-color-primary="custom" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#trustllm-trustworthiness-in-large-language-models" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="index.html" title="TrustLLM" class="md-header__button md-logo" aria-label="TrustLLM" data-md-component="logo">
      
  <img src="img.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            TrustLLM
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Home
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="black" data-md-color-primary="custom" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    
  
  
    <li class="md-tabs__item md-tabs__item--active">
      <a href="index.html" class="md-tabs__link">
        
  
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="guides/generation_details.html" class="md-tabs__link">
          
  
  
  Guide

        </a>
      </li>
    
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="changelog.html" class="md-tabs__link">
        
  
  
    
  
  Changelog

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="faq.html" class="md-tabs__link">
        
  
  
    
  
  FAQ

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
                
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" hidden>
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="index.html" title="TrustLLM" class="md-nav__button md-logo" aria-label="TrustLLM" data-md-component="logo">
      
  <img src="img.png" alt="logo">

    </a>
    TrustLLM
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="index.html" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#about" class="md-nav__link">
    <span class="md-ellipsis">
      About
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#before-evaluation" class="md-nav__link">
    <span class="md-ellipsis">
      Before Evaluation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Before Evaluation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#installation" class="md-nav__link">
    <span class="md-ellipsis">
      Installation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dataset-download" class="md-nav__link">
    <span class="md-ellipsis">
      Dataset Download
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#generation" class="md-nav__link">
    <span class="md-ellipsis">
      Generation
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#start-your-evaluation" class="md-nav__link">
    <span class="md-ellipsis">
      Start Your Evaluation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#dataset-task" class="md-nav__link">
    <span class="md-ellipsis">
      Dataset &amp; Task
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#leaderboard" class="md-nav__link">
    <span class="md-ellipsis">
      Leaderboard
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#citation" class="md-nav__link">
    <span class="md-ellipsis">
      Citation
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Guide
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Guide
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="guides/generation_details.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Generation
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="guides/evaluation.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Evaluation
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="changelog.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Changelog
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="faq.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    FAQ
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
                
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#about" class="md-nav__link">
    <span class="md-ellipsis">
      About
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#before-evaluation" class="md-nav__link">
    <span class="md-ellipsis">
      Before Evaluation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Before Evaluation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#installation" class="md-nav__link">
    <span class="md-ellipsis">
      Installation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dataset-download" class="md-nav__link">
    <span class="md-ellipsis">
      Dataset Download
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#generation" class="md-nav__link">
    <span class="md-ellipsis">
      Generation
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#start-your-evaluation" class="md-nav__link">
    <span class="md-ellipsis">
      Start Your Evaluation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#dataset-task" class="md-nav__link">
    <span class="md-ellipsis">
      Dataset &amp; Task
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#leaderboard" class="md-nav__link">
    <span class="md-ellipsis">
      Leaderboard
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#citation" class="md-nav__link">
    <span class="md-ellipsis">
      Citation
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  
  




<h1 id="trustllm-trustworthiness-in-large-language-models"><strong>TrustLLM: Trustworthiness in Large Language Models</strong><a class="headerlink" href="#trustllm-trustworthiness-in-large-language-models" title="Permanent link">&para;</a></h1>
<h2 id="about"><strong>About</strong><a class="headerlink" href="#about" title="Permanent link">&para;</a></h2>
<p>TrustLLM is a comprehensive study of trustworthiness in large language models (LLMs), including principles for different dimensions of trustworthiness, established benchmark, evaluation, and analysis of trustworthiness for mainstream LLMs, and discussion of open challenges and future directions. The document explains how to use the trustllm python package to help you assess the performance of your LLM in trustworthiness more quickly. For more details about TrustLLM, please refer to <a href="https://trustllmbenchmark.github.io/TrustLLM-Website/">this link</a>.</p>
<p><img src="https://raw.githubusercontent.com/TrustLLMBenchmark/TrustLLM-Website/main/img/logo.png" width="100%"></p>
<h2 id="before-evaluation"><strong>Before Evaluation</strong><a class="headerlink" href="#before-evaluation" title="Permanent link">&para;</a></h2>
<h3 id="installation"><strong>Installation</strong><a class="headerlink" href="#installation" title="Permanent link">&para;</a></h3>
<p>Create a new environment:</p>
<div class="highlight"><pre><span></span><code>conda<span class="w"> </span>create<span class="w"> </span>--name<span class="w"> </span>trustllm<span class="w"> </span><span class="nv">python</span><span class="o">=</span><span class="m">3</span>.9
</code></pre></div>
<p><strong>Installation via Github (recommended):</strong></p>
<div class="highlight"><pre><span></span><code>git<span class="w"> </span>clone<span class="w"> </span>git@github.com:HowieHwong/TrustLLM.git
<span class="nb">cd</span><span class="w"> </span>TrustLLM/trustllm_pkg
pip<span class="w"> </span>install<span class="w"> </span>.
</code></pre></div>
<p><strong>Installation via <code>pip</code> (deprecated):</strong></p>
<div class="highlight"><pre><span></span><code>pip<span class="w"> </span>install<span class="w"> </span>trustllm
</code></pre></div>
<p><strong>Installation via <code>conda</code> (deprecated):</strong></p>
<div class="highlight"><pre><span></span><code>conda<span class="w"> </span>install<span class="w"> </span>-c<span class="w"> </span>conda-forge<span class="w"> </span>trustllm
</code></pre></div>
<h3 id="dataset-download"><strong>Dataset Download</strong><a class="headerlink" href="#dataset-download" title="Permanent link">&para;</a></h3>
<ol>
<li>Download TrustLLM dataset from Github:</li>
</ol>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">trustllm.dataset_download</span><span class="w"> </span><span class="kn">import</span> <span class="n">download_dataset</span>

<span class="n">download_dataset</span><span class="p">(</span><span class="n">save_path</span><span class="o">=</span><span class="s1">&#39;save_path&#39;</span><span class="p">)</span>
</code></pre></div>
<ol>
<li>Download TrustLLM dataset from <a href="">Hugginface</a>.</li>
</ol>
<h3 id="generation"><strong>Generation</strong><a class="headerlink" href="#generation" title="Permanent link">&para;</a></h3>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please note that the LLM you use for evaluation should have a certain level of utility. If its generation/NLP capabilities are weak, it may bias the evaluation results (for example, many evaluation samples may be considered invalid).</p>
</div>
<p>We have added generation section from <a href="https://howiehwong.github.io/TrustLLM/changelog.html">version 0.2.0</a>. Start your generation from <a href="https://howiehwong.github.io/TrustLLM/guides/generation_details.html">this page</a>.</p>
<h2 id="start-your-evaluation"><strong>Start Your Evaluation</strong><a class="headerlink" href="#start-your-evaluation" title="Permanent link">&para;</a></h2>
<p>See <a href="guides/evaluation.html">this page</a> for more details.</p>
<h2 id="dataset-task"><strong>Dataset &amp; Task</strong><a class="headerlink" href="#dataset-task" title="Permanent link">&para;</a></h2>
<p><strong>Dataset overview</strong></p>
<table>
<thead>
<tr>
<th>Dataset</th>
<th>Description</th>
<th>Num.</th>
<th>Exist?</th>
<th>Section</th>
</tr>
</thead>
<tbody>
<tr>
<td>SQuAD2.0</td>
<td>It combines questions in SQuAD1.1 with over 50,000 unanswerable questions.</td>
<td>100</td>
<td>✓</td>
<td>Misinformation</td>
</tr>
<tr>
<td>CODAH</td>
<td>It contains 28,000 commonsense questions.</td>
<td>100</td>
<td>✓</td>
<td>Misinformation</td>
</tr>
<tr>
<td>HotpotQA</td>
<td>It contains 113k Wikipedia-based question-answer pairs for complex multi-hop reasoning.</td>
<td>100</td>
<td>✓</td>
<td>Misinformation</td>
</tr>
<tr>
<td>AdversarialQA</td>
<td>It contains 30,000 adversarial reading comprehension question-answer pairs.</td>
<td>100</td>
<td>✓</td>
<td>Misinformation</td>
</tr>
<tr>
<td>Climate-FEVER</td>
<td>It contains 7,675 climate change-related claims manually curated by human fact-checkers.</td>
<td>100</td>
<td>✓</td>
<td>Misinformation</td>
</tr>
<tr>
<td>SciFact</td>
<td>It contains 1,400 expert-written scientific claims pairs with evidence abstracts.</td>
<td>100</td>
<td>✓</td>
<td>Misinformation</td>
</tr>
<tr>
<td>COVID-Fact</td>
<td>It contains 4,086 real-world COVID claims.</td>
<td>100</td>
<td>✓</td>
<td>Misinformation</td>
</tr>
<tr>
<td>HealthVer</td>
<td>It contains 14,330 health-related claims against scientific articles.</td>
<td>100</td>
<td>✓</td>
<td>Misinformation</td>
</tr>
<tr>
<td>TruthfulQA</td>
<td>The multiple-choice questions to evaluate whether a language model is truthful in generating answers to questions.</td>
<td>352</td>
<td>✓</td>
<td>Hallucination</td>
</tr>
<tr>
<td>HaluEval</td>
<td>It contains 35,000 generated and human-annotated hallucinated samples.</td>
<td>300</td>
<td>✓</td>
<td>Hallucination</td>
</tr>
<tr>
<td>LM-exp-sycophancy</td>
<td>A dataset consists of human questions with one sycophancy response example and one non-sycophancy response example.</td>
<td>179</td>
<td>✓</td>
<td>Sycophancy</td>
</tr>
<tr>
<td>Opinion pairs</td>
<td>It contains 120 pairs of opposite opinions.</td>
<td>240</td>
<td>✗</td>
<td>Sycophancy</td>
</tr>
<tr>
<td>WinoBias</td>
<td>It contains 3,160 sentences, split for development and testing, created by researchers familiar with the project.</td>
<td>734</td>
<td>✓</td>
<td>Stereotype</td>
</tr>
<tr>
<td>StereoSet</td>
<td>It contains the sentences that measure model preferences across gender, race, religion, and profession.</td>
<td>734</td>
<td>✓</td>
<td>Stereotype</td>
</tr>
<tr>
<td>Adult</td>
<td>The dataset, containing attributes like sex, race, age, education, work hours, and work type, is utilized to predict salary levels for individuals.</td>
<td>810</td>
<td>✓</td>
<td>Disparagement</td>
</tr>
<tr>
<td>Jailbraek Trigger</td>
<td>The dataset contains the prompts based on 13 jailbreak attacks.</td>
<td>1300</td>
<td>✗</td>
<td>Jailbreak, Toxicity</td>
</tr>
<tr>
<td>Misuse (additional)</td>
<td>This dataset contains prompts crafted to assess how LLMs react when confronted by attackers or malicious users seeking to exploit the model for harmful purposes.</td>
<td>261</td>
<td>✗</td>
<td>Misuse</td>
</tr>
<tr>
<td>Do-Not-Answer</td>
<td>It is curated and filtered to consist only of prompts to which responsible LLMs do not answer.</td>
<td>344 + 95</td>
<td>✓</td>
<td>Misuse, Stereotype</td>
</tr>
<tr>
<td>AdvGLUE</td>
<td>A multi-task dataset with different adversarial attacks.</td>
<td>912</td>
<td>✓</td>
<td>Natural Noise</td>
</tr>
<tr>
<td>AdvInstruction</td>
<td>600 instructions generated by 11 perturbation methods.</td>
<td>1200</td>
<td>✗</td>
<td>Natural Noise</td>
</tr>
<tr>
<td>ToolE</td>
<td>A dataset with the users' queries which may trigger LLMs to use external tools.</td>
<td>241</td>
<td>✓</td>
<td>Out of Domain (OOD)</td>
</tr>
<tr>
<td>Flipkart</td>
<td>A product review dataset, collected starting from December 2022.</td>
<td>400</td>
<td>✓</td>
<td>Out of Domain (OOD)</td>
</tr>
<tr>
<td>DDXPlus</td>
<td>A 2022 medical diagnosis dataset comprising synthetic data representing about 1.3 million patient cases.</td>
<td>100</td>
<td>✓</td>
<td>Out of Domain (OOD)</td>
</tr>
<tr>
<td>ETHICS</td>
<td>It contains numerous morally relevant scenarios descriptions and their moral correctness.</td>
<td>500</td>
<td>✓</td>
<td>Implicit Ethics</td>
</tr>
<tr>
<td>Social Chemistry 101</td>
<td>It contains various social norms, each consisting of an action and its label.</td>
<td>500</td>
<td>✓</td>
<td>Implicit Ethics</td>
</tr>
<tr>
<td>MoralChoice</td>
<td>It consists of different contexts with morally correct and wrong actions.</td>
<td>668</td>
<td>✓</td>
<td>Explicit Ethics</td>
</tr>
<tr>
<td>ConfAIde</td>
<td>It contains the description of how information is used.</td>
<td>196</td>
<td>✓</td>
<td>Privacy Awareness</td>
</tr>
<tr>
<td>Privacy Awareness</td>
<td>It includes different privacy information queries about various scenarios.</td>
<td>280</td>
<td>✗</td>
<td>Privacy Awareness</td>
</tr>
<tr>
<td>Enron Email</td>
<td>It contains approximately 500,000 emails generated by employees of the Enron Corporation.</td>
<td>400</td>
<td>✓</td>
<td>Privacy Leakage</td>
</tr>
<tr>
<td>Xstest</td>
<td>It's a test suite for identifying exaggerated safety behaviors in LLMs.</td>
<td>200</td>
<td>✓</td>
<td>Exaggerated Safety</td>
</tr>
</tbody>
</table>
<p><strong>Task overview</strong></p>
<table>
<thead>
<tr>
<th>Task Name</th>
<th>Metrics</th>
<th>Type</th>
<th>Eval</th>
<th>Section</th>
</tr>
</thead>
<tbody>
<tr>
<td>Closed-book QA</td>
<td>Accuracy (↑)</td>
<td>Generation</td>
<td>○</td>
<td>Misinformation(Internal)</td>
</tr>
<tr>
<td>Fact-Checking</td>
<td>Macro F-1 (↑)</td>
<td>Classification</td>
<td>●</td>
<td>Misinformation(External)</td>
</tr>
<tr>
<td>Multiple Choice QA</td>
<td>Accuracy (↑)</td>
<td>Classification</td>
<td>●</td>
<td>Hallucination</td>
</tr>
<tr>
<td>Hallucination Classification</td>
<td>Accuracy (↑)</td>
<td>Classification</td>
<td>●</td>
<td>Hallucination</td>
</tr>
<tr>
<td>Persona Sycophancy</td>
<td>Embedding similarity (↑)</td>
<td>Generation</td>
<td>◐</td>
<td>Sycophancy</td>
</tr>
<tr>
<td>Opinion Sycophancy</td>
<td>Percentage change (↓)</td>
<td>Generation</td>
<td>○</td>
<td>Sycophancy</td>
</tr>
<tr>
<td>Factuality Correction</td>
<td>Percentage change (↑)</td>
<td>Generation</td>
<td>○</td>
<td>Adversarial Factuality</td>
</tr>
<tr>
<td>Jailbreak Attack Evaluation</td>
<td>RtA (↑)</td>
<td>Generation</td>
<td>○</td>
<td>Jailbreak</td>
</tr>
<tr>
<td>Toxicity Measurement</td>
<td>Toxicity Value (↓)</td>
<td>Generation</td>
<td>●</td>
<td>Toxicity</td>
</tr>
<tr>
<td>Misuse Evaluation</td>
<td>RtA (↑)</td>
<td>Generation</td>
<td>○</td>
<td>Misuse</td>
</tr>
<tr>
<td>Exaggerated Safety Evaluation</td>
<td>RtA (↓)</td>
<td>Generation</td>
<td>○</td>
<td>Exaggerated Safety</td>
</tr>
<tr>
<td>Agreement on Stereotypes</td>
<td>Accuracy (↑)</td>
<td>Generation</td>
<td>◐</td>
<td>Stereotype</td>
</tr>
<tr>
<td>Recognition of Stereotypes</td>
<td>Agreement Percentage (↓)</td>
<td>Classification</td>
<td>◐</td>
<td>Stereotype</td>
</tr>
<tr>
<td>Stereotype Query Test</td>
<td>RtA (↑)</td>
<td>Generation</td>
<td>○</td>
<td>Stereotype</td>
</tr>
<tr>
<td>Preference Selection</td>
<td>RtA (↑)</td>
<td>Generation</td>
<td>○</td>
<td>Preference</td>
</tr>
<tr>
<td>Salary Prediction</td>
<td>p-value (↑)</td>
<td>Generation</td>
<td>●</td>
<td>Disparagement</td>
</tr>
<tr>
<td>Adversarial Perturbation in Downstream Tasks</td>
<td>ASR (↓), RS (↑)</td>
<td>Generation</td>
<td>◐</td>
<td>Natural Noise</td>
</tr>
<tr>
<td>Adversarial Perturbation in Open-Ended Tasks</td>
<td>Embedding similarity (↑)</td>
<td>Generation</td>
<td>◐</td>
<td>Natural Noise</td>
</tr>
<tr>
<td>OOD Detection</td>
<td>RtA (↑)</td>
<td>Generation</td>
<td>○</td>
<td>Out of Domain (OOD)</td>
</tr>
<tr>
<td>OOD Generalization</td>
<td>Micro F1 (↑)</td>
<td>Classification</td>
<td>○</td>
<td>Out of Domain (OOD)</td>
</tr>
<tr>
<td>Agreement on Privacy Information</td>
<td>Pearson’s correlation (↑)</td>
<td>Classification</td>
<td>●</td>
<td>Privacy Awareness</td>
</tr>
<tr>
<td>Privacy Scenario Test</td>
<td>RtA (↑)</td>
<td>Generation</td>
<td>○</td>
<td>Privacy Awareness</td>
</tr>
<tr>
<td>Probing Privacy Information Usage</td>
<td>RtA (↑), Accuracy (↓)</td>
<td>Generation</td>
<td>◐</td>
<td>Privacy Leakage</td>
</tr>
<tr>
<td>Moral Action Judgement</td>
<td>Accuracy (↑)</td>
<td>Classification</td>
<td>◐</td>
<td>Implicit Ethics</td>
</tr>
<tr>
<td>Moral Reaction Selection (Low-Ambiguity)</td>
<td>Accuracy (↑)</td>
<td>Classification</td>
<td>◐</td>
<td>Explicit Ethics</td>
</tr>
<tr>
<td>Moral Reaction Selection (High-Ambiguity)</td>
<td>RtA (↑)</td>
<td>Generation</td>
<td>○</td>
<td>Explicit Ethics</td>
</tr>
<tr>
<td>Emotion Classification</td>
<td>Accuracy (↑)</td>
<td>Classification</td>
<td>●</td>
<td>Emotional Awareness</td>
</tr>
</tbody>
</table>
<h2 id="leaderboard"><strong>Leaderboard</strong><a class="headerlink" href="#leaderboard" title="Permanent link">&para;</a></h2>
<p>If you want to view the performance of all models or upload the performance of your LLM, please refer to <a href="https://trustllmbenchmark.github.io/TrustLLM-Website/leaderboard.html">this link</a>.</p>
<h2 id="citation"><strong>Citation</strong><a class="headerlink" href="#citation" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code>@misc{sun2024trustllm,
      title={TrustLLM: Trustworthiness in Large Language Models}, 
      author={Lichao Sun and Yue Huang and Haoran Wang and Siyuan Wu and Qihui Zhang and Chujie Gao and Yixin Huang and Wenhan Lyu and Yixuan Zhang and Xiner Li and Zhengliang Liu and Yixin Liu and Yijue Wang and Zhikun Zhang and Bhavya Kailkhura and Caiming Xiong and Chaowei Xiao and Chunyuan Li and Eric Xing and Furong Huang and Hao Liu and Heng Ji and Hongyi Wang and Huan Zhang and Huaxiu Yao and Manolis Kellis and Marinka Zitnik and Meng Jiang and Mohit Bansal and James Zou and Jian Pei and Jian Liu and Jianfeng Gao and Jiawei Han and Jieyu Zhao and Jiliang Tang and Jindong Wang and John Mitchell and Kai Shu and Kaidi Xu and Kai-Wei Chang and Lifang He and Lifu Huang and Michael Backes and Neil Zhenqiang Gong and Philip S. Yu and Pin-Yu Chen and Quanquan Gu and Ran Xu and Rex Ying and Shuiwang Ji and Suman Jana and Tianlong Chen and Tianming Liu and Tianyi Zhou and Willian Wang and Xiang Li and Xiangliang Zhang and Xiao Wang and Xing Xie and Xun Chen and Xuyu Wang and Yan Liu and Yanfang Ye and Yinzhi Cao and Yong Chen and Yue Zhao},
      year={2024},
      eprint={2401.05561},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
</code></pre></div>







  
  




  



                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2024 TrustLLM
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": ".", "features": ["navigation.tabs", "navigation.sections", "navigation.instant", "navigation.top", "navigation.tracking", "toc.follow"], "search": "assets/javascripts/workers/search.d50fe291.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="assets/javascripts/bundle.13a4f30d.min.js"></script>
      
        <script src="javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>